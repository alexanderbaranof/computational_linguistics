{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3==0.1.10\n",
      "  Downloading https://files.pythonhosted.org/packages/51/56/57e550b53587719e92330a79c7c0f555402d953b00700efae6d5ca53cdef/pymystem3-0.1.10-py3-none-any.whl\n",
      "Collecting requests (from pymystem3==0.1.10)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->pymystem3==0.1.10)\n",
      "  Using cached https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests->pymystem3==0.1.10)\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests->pymystem3==0.1.10)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests->pymystem3==0.1.10)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl\n",
      "Installing collected packages: urllib3, certifi, chardet, idna, requests, pymystem3\n",
      "Successfully installed certifi-2020.6.20 chardet-3.0.4 idna-2.10 pymystem3-0.2.0 requests-2.24.0 urllib3-1.25.11\n",
      "Collecting pymorphy2[fast]\n",
      "  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 659kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2[fast])\n",
      "  Using cached https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl\n",
      "Collecting docopt>=0.6 (from pymorphy2[fast])\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2[fast])\n",
      "  Using cached https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Collecting DAWG>=0.8; extra == \"fast\" (from pymorphy2[fast])\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz\n",
      "Building wheels for collected packages: DAWG\n",
      "  Running setup.py bdist_wheel for DAWG ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/alex/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
      "Successfully built DAWG\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, DAWG, pymorphy2\n",
      "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "Collecting razdel\n",
      "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
      "Installing collected packages: razdel\n",
      "Successfully installed razdel-0.5.0\n",
      "Collecting gensim\n",
      "  Using cached https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5.0 (from gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting scipy>=0.18.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.9MB 70kB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting numpy>=1.11.3 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/fc/36e52d0ae2aa502b211f1bcd2fdeec72d343d58224eabcdddc1bcb052db1/numpy-1.19.4-cp36-cp36m-manylinux1_x86_64.whl (13.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.4MB 141kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting requests (from smart-open>=1.8.1->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests->smart-open>=1.8.1->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->smart-open>=1.8.1->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests->smart-open>=1.8.1->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests->smart-open>=1.8.1->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: smart-open\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/alex/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
      "Successfully built smart-open\n",
      "Installing collected packages: chardet, urllib3, certifi, idna, requests, smart-open, six, numpy, scipy, gensim\n",
      "Successfully installed certifi-2020.6.20 chardet-3.0.4 gensim-3.8.3 idna-2.10 numpy-1.19.4 requests-2.24.0 scipy-1.5.4 six-1.15.0 smart-open-3.0.0 urllib3-1.25.11\n",
      "Collecting nltk\n",
      "Collecting click (from nltk)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting regex (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/9f/aad666560082cb11331167cbb31cf0e8bd90af8ea4951436d1fcb2ddde44/regex-2020.10.28-cp36-cp36m-manylinux1_x86_64.whl (666kB)\n",
      "\u001b[K    100% |████████████████████████████████| 675kB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Using cached https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl\n",
      "Installing collected packages: click, joblib, regex, tqdm, nltk\n",
      "Successfully installed click-7.1.2 joblib-0.17.0 nltk-3.5 regex-2020.10.28 tqdm-4.51.0\n",
      "Collecting rusenttokenize\n",
      "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
      "Installing collected packages: rusenttokenize\n",
      "Successfully installed rusenttokenize-0.0.5\n",
      "Collecting regex\n",
      "  Using cached https://files.pythonhosted.org/packages/87/9f/aad666560082cb11331167cbb31cf0e8bd90af8ea4951436d1fcb2ddde44/regex-2020.10.28-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2020.10.28\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pymystem3==0.1.10 --user\n",
    "!pip3 install pymorphy2[fast] --user\n",
    "!pip3 install razdel --user\n",
    "!pip3 install gensim --user\n",
    "!pip3 install nltk --user\n",
    "!pip3 install rusenttokenize --user\n",
    "!pip3 install regex --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from gensim.utils import tokenize\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "from rusenttokenize import ru_sent_tokenize\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "morph = MorphAnalyzer()\n",
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\n",
      "ERROR: could not open HSTS store at '/home/alex/.wget-hsts'. HSTS will be disabled.\n",
      "--2020-11-05 20:52:11--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/zhivago.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.12.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.12.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1965598 (1.9M) [text/plain]\n",
      "Saving to: ‘zhivago.txt’\n",
      "\n",
      "zhivago.txt         100%[===================>]   1.87M  7.18MB/s    in 0.3s    \n",
      "\n",
      "2020-11-05 20:52:11 (7.18 MB/s) - ‘zhivago.txt’ saved [1965598/1965598]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/zhivago.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\thw1.ipynb  zhivago.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('zhivago.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<author><first-name>Борис</first-name><middle-name>Леонидович</middle-name><last-name>Пастернак</las'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 100 symbols\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub('\\n', ' ', text)\n",
    "text = re.sub('<binary.*?</binary>', ' ', text)\n",
    "text = re.sub('<nickname.*?</nickname>', ' ', text)\n",
    "text = re.sub('<program-used.*?</program-used>', ' ', text)\n",
    "text = re.sub('<src-url.*?</src-url>', ' ', text)\n",
    "text = re.sub('<date.*?</date>', ' ', text)\n",
    "text = re.sub('<id.*?</id>', ' ', text)\n",
    "text = re.sub('<lang.*?</lang>', ' ', text)\n",
    "text = re.sub('<version.*?</version>', ' ', text)\n",
    "text = re.sub('<.*?>', ' ', text)\n",
    "text = re.sub(u'\\xa0', ' ', text)\n",
    "text = re.sub(' {2,}', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020144"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Борис Леонидович Пастернак Доктор Живаго «Доктор Живаго» - итоговое произведение Бориса Пастернака, книга всей его жизни. Этот роман принес его автору мировую известность и Нобелевскую премию, присуждение которой обернулось для поэта оголтелой политической травлей, обвинениями в «измене Родине» и в результате стоило ему жизни. «Доктор Живаго» - роман, сама ткань которого убедительнее свидетельствует о чуде, чем все размышления доктора и обобщения автора. Человек, который так пишет, бесконечно много пережил и передумал, и главные его чувства на свете - восхищенное умиление и слезное сострадание; конечно, есть в его мире место и презрению, и холодному отстранению - но не в них суть. Роман Пастернака - оплакивание прежних заблуждений и их жертв; те, кто не разделяет молитвенного восторга перед миром, достойны прежде всего жалости. Перечитывать «Доктора Живаго» стоит именно тогда, когда кажется, что жить не стоит. Тогда десять строк из этого романа могут сделать то же, что делает любовь в'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols to remove !\"#$%&'()*+,-/:;<=>?@[\\]^_`{|}~«»—…“”\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "\n",
    "remove = string.punctuation\n",
    "remove += '«»—…“”'\n",
    "remove = remove.replace('.', '')\n",
    "\n",
    "print('Symbols to remove', remove)\n",
    "\n",
    "#remove = dict.fromkeys(map(ord, remove), '')\n",
    "#text = text.translate(remove).strip()\n",
    "\n",
    "text = ' '.join([word.strip(remove) for word in text.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' борис леонидович пастернак доктор живаго доктор живаго  итоговое произведение бориса пастернака книга всей его жизни. этот роман принес его автору мировую известность и нобелевскую премию присуждение которой обернулось для поэта оголтелой политической травлей обвинениями в измене родине и в результате стоило ему жизни. доктор живаго  роман сама ткань которого убедительнее свидетельствует о чуде чем все размышления доктора и обобщения автора. человек который так пишет бесконечно много пережил и передумал и главные его чувства на свете  восхищенное умиление и слезное сострадание конечно есть в его мире место и презрению и холодному отстранению  но не в них суть. роман пастернака  оплакивание прежних заблуждений и их жертв те кто не разделяет молитвенного восторга перед миром достойны прежде всего жалости. перечитывать доктора живаго стоит именно тогда когда кажется что жить не стоит. тогда десять строк из этого романа могут сделать то же что делает любовь в одном из стихотворений доктора жизнь вернулась так же беспричинно как когда-то странно прервалась . борис пастернак доктор живаго и дышат почва и судьба спустя два года после завершения романа доктор живаго борис пастернак писал я думаю несмотря на привычность всего того что продолжает стоять перед нашими глазами и что мы продолжаем слышать и читать ничего этого больше нет это уже прошло и состоялось огромный неслыханных сил стоивший период закончился и миновал. освободилось безмерно большое покамест пустое и не занятое место для нового и еще не бывалого для того что будет угадано чьей-либо гениальной независимостью и свежестью для того что внушит и подскажет жизнь новых чисел и дней. сейчас мукою художников будет не то признаны ли они и признаны ли будут застаивающейся запоздалой политической современностью или властью но неспособность совершенно оторваться от понятий ставших привычными забыть навязывающиеся навыки нарушить непрерывность. надо понять что все стало прошлым что конец виденного и пережитого был уже '"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Something went wrong while tokenizing\n"
     ]
    }
   ],
   "source": [
    "sentences = ru_sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('да.', 10),\n",
       " ('– хорошо.', 6),\n",
       " ('– знаю.', 4),\n",
       " ('сеялки.', 4),\n",
       " ('молотилки».', 4),\n",
       " ('но дело не в этом.', 3),\n",
       " ('слушай.', 3),\n",
       " ('– еще бы.', 3),\n",
       " ('– да.', 3),\n",
       " ('– я знаю.', 3)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# поиск повторяющихся предложений\n",
    "c = Counter(sentences)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгляит абсолютном логичнм результат. Предложения только согласия встречается больше всего раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[token.text for token in list(razdel_tokenize(sent))] for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['доктор',\n",
       " 'живаго',\n",
       " 'роман',\n",
       " 'сама',\n",
       " 'ткань',\n",
       " 'которого',\n",
       " 'убедительнее',\n",
       " 'свидетельствует',\n",
       " 'о',\n",
       " 'чуде',\n",
       " 'чем',\n",
       " 'все',\n",
       " 'размышления',\n",
       " 'доктора',\n",
       " 'и',\n",
       " 'обобщения',\n",
       " 'автора',\n",
       " '.']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('андреевич', 289)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# поиск самого частотного токена больше длины 6\n",
    "acceptable_tokens = list()\n",
    "for sent in sentences:\n",
    "    for token in sent:\n",
    "        if len(token) > 6:\n",
    "            acceptable_tokens.append(token)\n",
    "\n",
    "c = Counter(acceptable_tokens)\n",
    "c.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('эт', 1924),\n",
       " ('он', 1243),\n",
       " ('был', 1200),\n",
       " ('ег', 1085),\n",
       " ('е', 781),\n",
       " ('котор', 634),\n",
       " ('юр', 562),\n",
       " ('сво', 559),\n",
       " ('друг', 458),\n",
       " ('говор', 391),\n",
       " ('так', 372),\n",
       " ('ил', 367),\n",
       " ('когд', 364),\n",
       " ('ещ', 352),\n",
       " ('как', 347),\n",
       " ('сам', 344),\n",
       " ('одн', 341),\n",
       " ('себ', 335),\n",
       " ('не', 326),\n",
       " ('чтоб', 324),\n",
       " ('ем', 319),\n",
       " ('теб', 294),\n",
       " ('мен', 293),\n",
       " ('тольк', 293),\n",
       " ('жизн', 283),\n",
       " ('больш', 283),\n",
       " ('врем', 267),\n",
       " ('рук', 266),\n",
       " ('лар', 257),\n",
       " ('дом', 250),\n",
       " ('тепер', 242),\n",
       " ('над', 241),\n",
       " ('сказа', 241),\n",
       " ('мо', 240),\n",
       " ('нег', 235),\n",
       " ('пот', 221),\n",
       " ('дел', 218),\n",
       " ('мест', 211),\n",
       " ('стал', 200),\n",
       " ('част', 200)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# простемим все токены и посмотрим на самые частотные\n",
    "acceptable_tokens = list()\n",
    "for sent in sentences:\n",
    "    for token in sent:\n",
    "        tmp_stem = stemmer.stem(token)\n",
    "        if token != tmp_stem:\n",
    "            acceptable_tokens.append(tmp_stem)\n",
    "\n",
    "c = Counter(acceptable_tokens)\n",
    "c.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кажется можно посмотреть на исхожные формы след. стемов: мен, стал\n",
    "\n",
    "result = {\n",
    "    'мен': set(),\n",
    "    'стал': set()\n",
    "}\n",
    "\n",
    "acceptable_tokens = list()\n",
    "for sent in sentences:\n",
    "    for token in sent:\n",
    "        tmp_stem = stemmer.stem(token)\n",
    "        if tmp_stem in result:\n",
    "            result[tmp_stem].add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'мен': {'мена', 'мене', 'менее', 'меня'},\n",
       " 'стал': {'стал', 'стала', 'стали', 'стало', 'сталось', 'сталь'}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "\n",
    "кажется, что я угадал. Стем \"стал\" приводит слова стал и сталь (абсолютно разные во всех смыслах) к одному. А также \"мен\" содержит в себе слова \"мена\", \"менее\" и \"меня\", и они тоже являются тремя разными словами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('андреевич', 289)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# простемим все токены и посмотрим на те, которые не изменились\n",
    "acceptable_tokens = list()\n",
    "for sent in sentences:\n",
    "    for token in sent:\n",
    "        tmp_stem = stemmer.stem(token)\n",
    "        if token == tmp_stem and len(tmp_stem) > 4:\n",
    "            acceptable_tokens.append(tmp_stem)\n",
    "\n",
    "c = Counter(acceptable_tokens)\n",
    "c.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резултат похож на поиск самого частотного токена больше длины 6. Тут snowball не отработал, но при этом слово является одним из самых частых."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "stops = stopwords.words('russian')\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предлагаю также добавить в стоп. слова:\n",
    "- нибудь | т.к. часть слова может остаться при неправильной пред. обработки\n",
    "- это | т.к. частица не несет смысла\n",
    "- также | т.к. союз и не несет смысла \n",
    "- либо | т.к. союз и не несет смысла \n",
    "- ко | и в целом все предлоги с \"о\" которых нет в списке стоп-слов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_tokens = list()\n",
    "for sent in sentences:\n",
    "    for token in sent:\n",
    "        morph_token = morph.parse(token)[0].normal_form\n",
    "        mystem_token = mystem.lemmatize(token)[0]\n",
    "        if morph_token != mystem_token:\n",
    "            tmp_str = f'token:{token},morph:{morph_token},mystem:{mystem_token}'\n",
    "            acceptable_tokens.append(tmp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('token:–,morph:–,mystem:–\\n', 2421),\n",
       " ('token:все,morph:всё,mystem:все', 761),\n",
       " ('token:еще,morph:ещё,mystem:еще', 352),\n",
       " ('token:со,morph:с,mystem:со', 235),\n",
       " ('token:во,morph:в,mystem:во', 207),\n",
       " ('token:чем,morph:чем,mystem:что', 204),\n",
       " ('token:»,morph:»,mystem:»\\n', 198),\n",
       " ('token:может,morph:мочь,mystem:может', 162),\n",
       " ('token:ним,morph:они,mystem:он', 161),\n",
       " ('token:больше,morph:большой,mystem:больше', 142),\n",
       " ('token:того,morph:тот,mystem:то', 133),\n",
       " ('token:есть,morph:есть,mystem:быть', 117),\n",
       " ('token:всех,morph:весь,mystem:все', 114),\n",
       " ('token:тем,morph:тем,mystem:то', 108),\n",
       " ('token:стал,morph:стать,mystem:становиться', 103),\n",
       " ('token:дома,morph:дом,mystem:дома', 97),\n",
       " ('token:всем,morph:весь,mystem:все', 97),\n",
       " ('token:об,morph:о,mystem:об', 88),\n",
       " ('token:стало,morph:стать,mystem:становиться', 85),\n",
       " ('token:том,morph:тот,mystem:том', 76),\n",
       " ('token:всего,morph:весь,mystem:всего', 72),\n",
       " ('token:стали,morph:стать,mystem:становиться', 67),\n",
       " ('token:свете,morph:свет,mystem:света', 64),\n",
       " ('token:лучше,morph:хороший,mystem:хорошо', 64),\n",
       " ('token:дальше,morph:далёкий,mystem:далеко', 60),\n",
       " ('token:кажется,morph:казаться,mystem:кажется', 49),\n",
       " ('token:стала,morph:стать,mystem:становиться', 46),\n",
       " ('token:федоровна,morph:фёдорович,mystem:федоровна', 45),\n",
       " ('token:всеми,morph:весь,mystem:все', 42),\n",
       " ('token:ночью,morph:ночью,mystem:ночь', 41),\n",
       " ('token:раньше,morph:ранний,mystem:рано', 38),\n",
       " ('token:свое,morph:свой,mystem:свое', 37),\n",
       " ('token:вперед,morph:вперёд,mystem:вперед', 37),\n",
       " ('token:тому,morph:тот,mystem:то', 36),\n",
       " ('token:всему,morph:весь,mystem:все', 36),\n",
       " ('token:антонина,morph:антонин,mystem:антонина', 31),\n",
       " ('token:александровна,morph:александрович,mystem:александровна', 31),\n",
       " ('token:антипова,morph:антипов,mystem:антипова', 30),\n",
       " ('token:скорее,morph:скорее,mystem:скоро', 30),\n",
       " ('token:ко,morph:к,mystem:ко', 29),\n",
       " ('token:вышел,morph:выйти,mystem:выходить', 29),\n",
       " ('token:этому,morph:этот,mystem:это', 29),\n",
       " ('token:дети,morph:ребёнок,mystem:ребенок', 29),\n",
       " ('token:лары,morph:лара,mystem:лары', 28),\n",
       " ('token:антипов,morph:антип,mystem:антипов', 28),\n",
       " ('token:деньги,morph:деньга,mystem:деньги', 28),\n",
       " ('token:отчего,morph:отчий,mystem:отчего', 28),\n",
       " ('token:юрочка,morph:юрочко,mystem:юрочка', 27),\n",
       " ('token:стоит,morph:стоить,mystem:стоять', 26),\n",
       " ('token:утром,morph:утром,mystem:утро', 26)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(acceptable_tokens)\n",
    "c.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примерах ниже видно, что pymorphy2 приводит все к мужскому роду, хотя в контексте книги это могут быть разные персонажи\n",
    "- ('token:федоровна,morph:фёдорович,mystem:федоровна', 45)\n",
    "- ('token:антипова,morph:антипов,mystem:антипова', 30),\n",
    "\n",
    "Буква Ё:\n",
    "- ('token:все,morph:всё,mystem:все', 761),\n",
    "- ('token:еще,morph:ещё,mystem:еще', 352),\n",
    "\n",
    "Т.е. pymorphy2 добавляет букву ё даже когда ее нет в тексте, что считаю неправильным\n",
    "\n",
    "Удаление буквы о в предлогах у pymorphy2. Это также считаю проблемой так как это уже разные токены.\n",
    "- ('token:во,morph:в,mystem:во', 207),\n",
    "- ('token:ко,morph:к,mystem:ко', 29),\n",
    "\n",
    "Неуместное приведение к множественному числу у pymorphy2 :\n",
    "- ('token:ним,morph:они,mystem:он', 161),\n",
    "\n",
    "Вывод: для обработки данноо текста лучше использовать mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
