{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13efba76",
   "metadata": {},
   "source": [
    "# Дисклеймер\n",
    "Эту тетрадку нужно запускать в колабе или в vast.ai. Не мучатесь с установкой библиотек и с обучением на cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d650e9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (8.1.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 17.2 MB/s eta 0:00:01     |█████████████████▌              | 13.6 MB 17.2 MB/s eta 0:00:01     |█████████████████████████       | 19.5 MB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.2 MB 14.2 MB/s eta 0:00:01    |██▋                             | 2.3 MB 14.2 MB/s eta 0:00:02\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=d2b555d82c2734c6d1df69cc21d9e6d6fc536547b7a5e92e6e9a4a67a77422fd\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: tokenizers, kiwisolver, cycler, matplotlib, joblib, threadpoolctl, scipy, scikit-learn, sklearn\n",
      "Successfully installed cycler-0.10.0 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.4.2 scikit-learn-0.24.2 scipy-1.6.3 sklearn-0.0 threadpoolctl-2.1.0 tokenizers-0.10.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в vast ai или в последних версия jupyter может не работать автозаполнение, установка этой либы и перезагрука кернела помогает\n",
    "# !pip install --upgrade jedi==0.17.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384bd5c",
   "metadata": {},
   "source": [
    "# Транформеры для решения seq2seq задач"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69baacc",
   "metadata": {},
   "source": [
    "Seq2seq - наверное самая общая формальная постановка задачи в NLP. Нужно из произвольной последовательности получить какую-то другую последовательность. И в отличие от разметки последовательности (sequence labelling) не требуется, чтобы обе последовательности совпадали по длине. Даже стандартную задачу классификации можно решать как seq2seq - можно рассматривать метку класса как последовательность длинны 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a0525",
   "metadata": {},
   "source": [
    "А трансформеры - sota архитектура для seq2seq задач. Мы не будем подробно разбирать устройство транформеров, если вам интересно вы можете поразбираться вот с этими материалами:\n",
    "\n",
    "Оригинальная статья (сложновато) - https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/  \n",
    "https://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "https://www.youtube.com/watch?v=iDulhoQ2pro\n",
    "\n",
    "https://www.youtube.com/watch?v=TQQlZhbC5ps\n",
    "\n",
    "Самый известный туториал (на торче) - https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "\n",
    "\n",
    "\n",
    "Трансформеры будут подробно разбираться на курсе глубокого обучения (по выбору) на втором курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c794a6",
   "metadata": {},
   "source": [
    "Пока просто попробуем обучать модель на задаче машинного перевода. Для таких задач лучше всего использовать предобученные модели, но если у вас будет какая-то специфичная seq2seq задача, то имеет смысл попробовать обучить трансформер с нуля и в этой тертрадке вам нужно будет поменять только часть с загрузкой данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947b3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415f5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в русскоязычных данных есть \\xa0 вместо пробелов, он может некорректно обрабатываться токенизатором\n",
    "# text = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ')\n",
    "# text = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ')\n",
    "# f = open('opus.en-ru-train.ru.txt', 'w')\n",
    "# f.write(text)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d83aa",
   "metadata": {},
   "source": [
    "Данные взяты вот отсюда - https://opus.nlpl.eu/opus-100.php (раздел с отдельными языковыми парами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e110ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sents = open('opus.en-ru-train.en.txt').read().splitlines()\n",
    "ru_sents = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ').splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009c96e",
   "metadata": {},
   "source": [
    "Пример перевода с английского на русский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb9b498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('So what are you thinking?', 'Ну и что ты думаешь?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sents[-1], ru_sents[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39921c4",
   "metadata": {},
   "source": [
    "Как обычно нам нужен токенизатор, а точнее даже 2, т.к. у нас два корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b79b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(BPE())\n",
    "tokenizer_en.pre_tokenizer = Whitespace()\n",
    "trainer_en = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer_en.train(files=[\"opus.en-ru-train.en.txt\"], trainer=trainer_en)\n",
    "\n",
    "tokenizer_ru = Tokenizer(BPE())\n",
    "tokenizer_ru.pre_tokenizer = Whitespace()\n",
    "trainer_ru = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer_ru.train(files=[\"opus.en-ru-train.ru.txt\"], trainer=trainer_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48780b24",
   "metadata": {},
   "source": [
    "### ВАЖНО!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b56d3b",
   "metadata": {},
   "source": [
    "Токенизатор - это неотъемлимая часть модели, поэтому не забывайте сохранять токенизатор вместе с моделью. Если вы забудете про это и переобучите токенизатор, то индексы токенов разойдутся и веса модели будут бесполезны. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd90665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# раскоментируйте эту ячейку при обучении токенизатора\n",
    "# а потом снова закоментируйте чтобы при перезапуске не перезаписать токенизаторы\n",
    "tokenizer_en.save('tokenizer_en')\n",
    "tokenizer_ru.save('tokenizer_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0f7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
    "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fecf3",
   "metadata": {},
   "source": [
    "Переводим текст в индексы вот таким образом. В начало добавляем токен '[CLS]', а в конец '[SEP]'. Если вспомните занятие по языковому моделированию, то там мы добавляли \"\\<start>\" и \"\\<end>\" - cls и sep по сути тоже самое. Вы поймете почему именно cls и sep, а не start и end, если подробнее поразбираетесь с устройством трансформеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc003758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, tokenizer, max_len):\n",
    "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[SEP]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96920fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важно следить чтобы индекс паддинга совпадал в токенизаторе с value в pad_sequences\n",
    "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc0a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ограничимся длинной в 30 и 35 (разные чтобы показать что в seq2seq не нужна одинаковая длина)\n",
    "max_len_en, max_len_ru = 30, 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc2dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en = [encode(t, tokenizer_en, max_len_en) for t in en_sents]\n",
    "X_ru = [encode(t, tokenizer_ru, max_len_ru) for t in ru_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68091524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7655a4ea",
   "metadata": {},
   "source": [
    "Паддинг внутри класса для датасета. Еще обратите внимание, что тут не стоит параметр batch_first=True как раньше\n",
    "\n",
    "В торче принято, что размерность батча идет в конце и пример кода с трансформером расчитан на это. Конечно можно поменять сам код модели, но это сложнее, чем просто изменить тензор с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7634853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, texts_en, texts_ru):\n",
    "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
    "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, padding_value=PAD_IDX)\n",
    "        \n",
    "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
    "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, padding_value=PAD_IDX)\n",
    "\n",
    "        self.length = len(texts_en)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        ids_en = self.texts_en[:, index]\n",
    "        ids_ru = self.texts_ru[:, index]\n",
    "\n",
    "        return ids_en, ids_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec889a8d",
   "metadata": {},
   "source": [
    "Разбиваем на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c9eaf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_train, X_en_valid, X_ru_train, X_ru_valid = train_test_split(X_en, X_ru, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f0fcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(X_en_train, X_ru_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0980a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = Dataset(X_en_valid, X_ru_valid)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb0e70",
   "metadata": {},
   "source": [
    "# Код трансформера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a83a16",
   "metadata": {},
   "source": [
    "Дальше код модели, он взят вот отсюда (с небольшими изменениями) - https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "Там есть комментарии по каждому этапу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "078605bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 150):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size, \n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "#         print('pos inp')\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "#         print('pos dec')\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "#         print('pos out')\n",
    "        x = self.generator(outs)\n",
    "#         print('gen')\n",
    "        return x\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "# During training, we need a subsequent word mask that will prevent model to look into the future words when making predictions. We will also need masks to hide source and target padding tokens. Below, let’s define a function that will take care of both.\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    \n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05d7f6",
   "metadata": {},
   "source": [
    "Обратите внимание на то как мы подаем данные в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedf9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, iterator, optimizer, criterion, print_every=500):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    ac = []\n",
    "    \n",
    "    model.train()  \n",
    "\n",
    "    for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "        texts_en = texts_en.T.to(DEVICE) # чтобы батч был в конце\n",
    "        texts_ru = texts_ru.T.to(DEVICE) # чтобы батч был в конце\n",
    "        \n",
    "        # помимо текста в модель еще нужно передать целевую последовательность\n",
    "        # но не полную а без 1 последнего элемента\n",
    "        # а на выходе ожидаем, что модель сгенерирует этот недостающий элемент\n",
    "        texts_ru_input = texts_ru[:-1, :]\n",
    "        \n",
    "        \n",
    "        # в трансформерах нет циклов как в лстм \n",
    "        # каждый элемент связан с каждым через аттеншен\n",
    "        # чтобы имитировать последовательную обработку\n",
    "        # и чтобы не считать аттеншн с паддингом \n",
    "        # в трансформерах нужно считать много масок\n",
    "        # подробнее про это по ссылкам выше\n",
    "        (texts_en_mask, texts_ru_mask, \n",
    "        texts_en_padding_mask, texts_ru_padding_mask) = create_mask(texts_en, texts_ru_input)\n",
    "        logits = model(texts_en, texts_ru_input, texts_en_mask, texts_ru_mask,\n",
    "                       texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # сравниваем выход из модели с целевой последовательностью уже с этим последним элементом\n",
    "        texts_ru_out = texts_ru[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_ru_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(f'Loss: {np.mean(epoch_loss)};')\n",
    "        \n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_f1 = []\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "            texts_en = texts_en.T.to(DEVICE)\n",
    "            texts_ru = texts_ru.T.to(DEVICE)\n",
    "\n",
    "            texts_ru_input = texts_ru[:-1, :]\n",
    "\n",
    "            (texts_en_mask, texts_ru_mask, \n",
    "            texts_en_padding_mask, texts_ru_padding_mask) = create_mask(texts_en, texts_ru_input)\n",
    "\n",
    "            logits = model(texts_en, texts_ru_input, texts_en_mask, texts_ru_mask,\n",
    "                           texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "\n",
    "            \n",
    "            texts_ru_out = texts_ru[1:, :]\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_ru_out.reshape(-1))\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697183c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4ea391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "EN_VOCAB_SIZE = tokenizer_en.get_vocab_size()\n",
    "RU_VOCAB_SIZE = tokenizer_ru.get_vocab_size()\n",
    "\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, EN_VOCAB_SIZE, RU_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07f5b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(transformer, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d39a4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = torch.load('model').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5559362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2070ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.777023684501648;\n",
      "Loss: 7.189187149524689;\n",
      "Loss: 6.86022801399231;\n",
      "Loss: 6.625767652273178;\n",
      "Loss: 6.443910612297058;\n",
      "Loss: 6.292123263835907;\n",
      "Loss: 6.162796253749303;\n",
      "Loss: 6.049368862390518;\n",
      "Loss: 5.948034999635484;\n",
      "First epoch - 4.881634845733642, saving model..\n",
      "Epoch: 1, Train loss: 5.901, Val loss: 4.882,            Epoch time=373.023s\n",
      "Loss: 4.9371407995224;\n",
      "Loss: 4.888275605201721;\n",
      "Loss: 4.840170733451843;\n",
      "Loss: 4.796880114793778;\n",
      "Loss: 4.75520146484375;\n",
      "Loss: 4.713666047890981;\n",
      "Loss: 4.673826389721461;\n",
      "Loss: 4.6358319303989415;\n",
      "Loss: 4.5988356710010105;\n",
      "Improved from 4.881634845733642 to 4.067133041381836, saving model..\n",
      "Epoch: 2, Train loss: 4.581, Val loss: 4.067,            Epoch time=379.522s\n",
      "Loss: 4.1600327067375185;\n",
      "Loss: 4.13209522986412;\n",
      "Loss: 4.112308955510457;\n",
      "Loss: 4.087118461251259;\n",
      "Loss: 4.064487071800232;\n",
      "Loss: 4.042235009829203;\n",
      "Loss: 4.020630682264056;\n",
      "Loss: 4.000355663776397;\n",
      "Loss: 3.9796124303076;\n",
      "Improved from 4.067133041381836 to 3.6068692636489867, saving model..\n",
      "Epoch: 3, Train loss: 3.969, Val loss: 3.607,            Epoch time=380.339s\n",
      "Loss: 3.684978108882904;\n",
      "Loss: 3.677020972251892;\n",
      "Loss: 3.667083053270976;\n",
      "Loss: 3.6542957544326784;\n",
      "Loss: 3.642649124622345;\n",
      "Loss: 3.6303877900441486;\n",
      "Loss: 3.6177928752217974;\n",
      "Loss: 3.6057599224448205;\n",
      "Loss: 3.5932431835068597;\n",
      "Improved from 3.6068692636489867 to 3.32320481967926, saving model..\n",
      "Epoch: 4, Train loss: 3.588, Val loss: 3.323,            Epoch time=365.305s\n",
      "Loss: 3.3800194606781004;\n",
      "Loss: 3.3792972111701967;\n",
      "Loss: 3.3737793057759604;\n",
      "Loss: 3.370519346356392;\n",
      "Loss: 3.364118836307526;\n",
      "Loss: 3.359489014228185;\n",
      "Loss: 3.3541073753493174;\n",
      "Loss: 3.3482186521291735;\n",
      "Loss: 3.3423030104107325;\n",
      "Improved from 3.32320481967926 to 3.140442808151245, saving model..\n",
      "Epoch: 5, Train loss: 3.339, Val loss: 3.140,            Epoch time=365.474s\n",
      "Loss: 3.192933078765869;\n",
      "Loss: 3.18831018280983;\n",
      "Loss: 3.185575747013092;\n",
      "Loss: 3.1839150476455687;\n",
      "Loss: 3.1822026676177977;\n",
      "Loss: 3.179546586751938;\n",
      "Loss: 3.1771940514019557;\n",
      "Loss: 3.1740657628178597;\n",
      "Loss: 3.1705349109437733;\n",
      "Improved from 3.140442808151245 to 3.0250268630981445, saving model..\n",
      "Epoch: 6, Train loss: 3.169, Val loss: 3.025,            Epoch time=378.349s\n",
      "Loss: 3.0329187693595885;\n",
      "Loss: 3.04545668721199;\n",
      "Loss: 3.048223278045654;\n",
      "Loss: 3.049536032438278;\n",
      "Loss: 3.049312315940857;\n",
      "Loss: 3.048896491209666;\n",
      "Loss: 3.048358749934605;\n",
      "Loss: 3.0485075363516807;\n",
      "Loss: 3.047023626592424;\n",
      "Improved from 3.0250268630981445 to 2.941042469024658, saving model..\n",
      "Epoch: 7, Train loss: 3.046, Val loss: 2.941,            Epoch time=377.057s\n",
      "Loss: 2.939214346408844;\n",
      "Loss: 2.9411160917282104;\n",
      "Loss: 2.9434169160525006;\n",
      "Loss: 2.947036077260971;\n",
      "Loss: 2.9488117668151856;\n",
      "Loss: 2.9495998655955;\n",
      "Loss: 2.9486406982966833;\n",
      "Loss: 2.9500021550655364;\n",
      "Loss: 2.9503196733792625;\n",
      "Improved from 2.941042469024658 to 2.8770966567993166, saving model..\n",
      "Epoch: 8, Train loss: 2.951, Val loss: 2.877,            Epoch time=375.060s\n",
      "Loss: 2.853581977844238;\n",
      "Loss: 2.858954399347305;\n",
      "Loss: 2.8644773138364155;\n",
      "Loss: 2.8680437279939652;\n",
      "Loss: 2.870738184452057;\n",
      "Loss: 2.8723064924081165;\n",
      "Loss: 2.8748349338259014;\n",
      "Loss: 2.875378409743309;\n",
      "Loss: 2.8765142805841233;\n",
      "Improved from 2.8770966567993166 to 2.8330052127838137, saving model..\n",
      "Epoch: 9, Train loss: 2.877, Val loss: 2.833,            Epoch time=376.633s\n",
      "Loss: 2.787772964000702;\n",
      "Loss: 2.7961885578632355;\n",
      "Loss: 2.8015767113367716;\n",
      "Loss: 2.803397532939911;\n",
      "Loss: 2.808144292163849;\n",
      "Loss: 2.8103009089628856;\n",
      "Loss: 2.8132399335588727;\n",
      "Loss: 2.8155003086924553;\n",
      "Loss: 2.815316737545861;\n",
      "Improved from 2.8330052127838137 to 2.7939400606155393, saving model..\n",
      "Epoch: 10, Train loss: 2.816, Val loss: 2.794,            Epoch time=372.492s\n",
      "Loss: 2.725672291278839;\n",
      "Loss: 2.733043817996979;\n",
      "Loss: 2.7402714522679648;\n",
      "Loss: 2.7460891709327697;\n",
      "Loss: 2.7492875450134275;\n",
      "Loss: 2.753269657055537;\n",
      "Loss: 2.7566109016282216;\n",
      "Loss: 2.760192204773426;\n",
      "Loss: 2.763373259173499;\n",
      "Improved from 2.7939400606155393 to 2.7662179708480834, saving model..\n",
      "Epoch: 11, Train loss: 2.765, Val loss: 2.766,            Epoch time=383.621s\n",
      "Loss: 2.6822331852912904;\n",
      "Loss: 2.6921478328704835;\n",
      "Loss: 2.697766921520233;\n",
      "Loss: 2.702902940988541;\n",
      "Loss: 2.706711034488678;\n",
      "Loss: 2.7100983833471934;\n",
      "Loss: 2.7131162068503243;\n",
      "Loss: 2.7164910250902174;\n",
      "Loss: 2.7189913623597888;\n",
      "Improved from 2.7662179708480834 to 2.7353617687225342, saving model..\n",
      "Epoch: 12, Train loss: 2.720, Val loss: 2.735,            Epoch time=387.819s\n",
      "Loss: 2.643672665596008;\n",
      "Loss: 2.653489919900894;\n",
      "Loss: 2.6563376232783;\n",
      "Loss: 2.6614466474056244;\n",
      "Loss: 2.6680472011566163;\n",
      "Loss: 2.672082998116811;\n",
      "Loss: 2.674208708354405;\n",
      "Loss: 2.678698772370815;\n",
      "Loss: 2.6813924029138354;\n",
      "Improved from 2.7353617687225342 to 2.713796034812927, saving model..\n",
      "Epoch: 13, Train loss: 2.683, Val loss: 2.714,            Epoch time=386.063s\n",
      "Loss: 2.60620241355896;\n",
      "Loss: 2.6135303995609283;\n",
      "Loss: 2.622508227189382;\n",
      "Loss: 2.625894487977028;\n",
      "Loss: 2.6311576736450197;\n",
      "Loss: 2.635532672961553;\n",
      "Loss: 2.6396400277273995;\n",
      "Loss: 2.6430608186125757;\n",
      "Loss: 2.6469409116109213;\n",
      "Improved from 2.713796034812927 to 2.6973124885559083, saving model..\n",
      "Epoch: 14, Train loss: 2.649, Val loss: 2.697,            Epoch time=381.961s\n",
      "Loss: 2.577475336074829;\n",
      "Loss: 2.58262814283371;\n",
      "Loss: 2.5910286812782286;\n",
      "Loss: 2.5978100410699843;\n",
      "Loss: 2.602367064857483;\n",
      "Loss: 2.6079556812445324;\n",
      "Loss: 2.6110607077053616;\n",
      "Loss: 2.6148030493855474;\n",
      "Loss: 2.618516584661272;\n",
      "Improved from 2.6973124885559083 to 2.6788983526229857, saving model..\n",
      "Epoch: 15, Train loss: 2.620, Val loss: 2.679,            Epoch time=386.122s\n",
      "Loss: 2.547933213233948;\n",
      "Loss: 2.5555155169963837;\n",
      "Loss: 2.56337939119339;\n",
      "Loss: 2.5697898842096327;\n",
      "Loss: 2.5764413388252256;\n",
      "Loss: 2.581409574508667;\n",
      "Loss: 2.585071597439902;\n",
      "Loss: 2.5894596326351165;\n",
      "Loss: 2.5928754750887553;\n",
      "Improved from 2.6788983526229857 to 2.671286413192749, saving model..\n",
      "Epoch: 16, Train loss: 2.594, Val loss: 2.671,            Epoch time=378.233s\n",
      "Loss: 2.5235437693595886;\n",
      "Loss: 2.53008583855629;\n",
      "Loss: 2.541161422888438;\n",
      "Loss: 2.5471273806095125;\n",
      "Loss: 2.5517594339370726;\n",
      "Loss: 2.556724931081136;\n",
      "Loss: 2.5610402754374912;\n",
      "Loss: 2.564953159630299;\n",
      "Loss: 2.5687678626908195;\n",
      "Improved from 2.671286413192749 to 2.65420122718811, saving model..\n",
      "Epoch: 17, Train loss: 2.571, Val loss: 2.654,            Epoch time=377.961s\n",
      "Loss: 2.5046861724853517;\n",
      "Loss: 2.507607264995575;\n",
      "Loss: 2.517270181655884;\n",
      "Loss: 2.523042123913765;\n",
      "Loss: 2.528904044723511;\n",
      "Loss: 2.535846060593923;\n",
      "Loss: 2.5396037368093216;\n",
      "Loss: 2.5444233360290527;\n",
      "Loss: 2.5486168615553115;\n",
      "Improved from 2.65420122718811 to 2.644679691314697, saving model..\n",
      "Epoch: 18, Train loss: 2.550, Val loss: 2.645,            Epoch time=384.802s\n",
      "Loss: 2.472489287853241;\n",
      "Loss: 2.4849136056900023;\n",
      "Loss: 2.491649954319;\n",
      "Loss: 2.5007851164340975;\n",
      "Loss: 2.509760618305206;\n",
      "Loss: 2.514776986996333;\n",
      "Loss: 2.520192477090018;\n",
      "Loss: 2.524569146811962;\n",
      "Loss: 2.5286759424209593;\n",
      "Improved from 2.644679691314697 to 2.636023578643799, saving model..\n",
      "Epoch: 19, Train loss: 2.531, Val loss: 2.636,            Epoch time=367.790s\n",
      "Loss: 2.4621076555252075;\n",
      "Loss: 2.472075161218643;\n",
      "Loss: 2.480357275168101;\n",
      "Loss: 2.4867244958877563;\n",
      "Loss: 2.492853923034668;\n",
      "Loss: 2.498535248597463;\n",
      "Loss: 2.503263192176819;\n",
      "Loss: 2.5072710828185083;\n",
      "Loss: 2.5115249677764044;\n",
      "Improved from 2.636023578643799 to 2.625261399269104, saving model..\n",
      "Epoch: 20, Train loss: 2.514, Val loss: 2.625,            Epoch time=372.584s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train(transformer, training_generator, optimizer, loss_fn)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer, valid_generator, loss_fn)\n",
    "    \n",
    "    if not losses:\n",
    "        print(f'First epoch - {val_loss}, saving model..')\n",
    "        torch.save(transformer, 'model')\n",
    "    \n",
    "    elif val_loss < min(losses):\n",
    "        print(f'Improved from {min(losses)} to {val_loss}, saving model..')\n",
    "        torch.save(transformer, 'model')\n",
    "    \n",
    "    losses.append(val_loss)\n",
    "        \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
    "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a21a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "\n",
    "\n",
    "    input_ids = [tokenizer_en.token_to_id('[CLS]')] + tokenizer_en.encode(text).ids[:max_len_en] + [tokenizer_en.token_to_id('[SEP]')]\n",
    "    output_ids = [tokenizer_ru.token_to_id('[CLS]')]\n",
    "\n",
    "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(input_ids)]).to(DEVICE)\n",
    "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)]).to(DEVICE)\n",
    "\n",
    "    (texts_en_mask, texts_ru_mask, \n",
    "    texts_en_padding_mask, texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "    logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_ru_mask,\n",
    "                   texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "    pred = logits.argmax(2).item()\n",
    "    print(output_ids)\n",
    "    print(pred)\n",
    "\n",
    "    while pred not in [tokenizer_ru.token_to_id('[SEP]'), tokenizer_ru.token_to_id('[PAD]')]:\n",
    "        output_ids.append(pred)\n",
    "        \n",
    "        print(output_ids)\n",
    "        \n",
    "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)]).to(DEVICE)\n",
    "\n",
    "        (texts_en_mask, texts_ru_mask, \n",
    "        texts_en_padding_mask, texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "        logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_ru_mask,\n",
    "                       texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "        pred = logits.argmax(2)[-1].item()\n",
    "\n",
    "    return (' '.join([tokenizer_ru.id_to_token(i).replace('##', '') for i in output_ids[1:]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "charming-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "governmental-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newtranslate(text):\n",
    "    \n",
    "    sents = sent_tokenize(text)\n",
    "    \n",
    "    len_sent = len(sents)\n",
    "    \n",
    "    to_pad_input = list()\n",
    "    to_pad_output = list()\n",
    "    \n",
    "    for sent in sents:\n",
    "        to_pad_input.append([tokenizer_en.token_to_id('[CLS]')] + tokenizer_en.encode(sent).ids[:max_len_en] + [tokenizer_en.token_to_id('[SEP]')])\n",
    "        to_pad_output.append([tokenizer_ru.token_to_id('[CLS]')])\n",
    "        \n",
    "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(tpi) for tpi in to_pad_input]).to(DEVICE)\n",
    "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(tpo) for tpo in to_pad_output]).to(DEVICE)\n",
    "\n",
    "    \n",
    "    (texts_en_mask,\n",
    "     texts_ru_mask,\n",
    "     texts_en_padding_mask,\n",
    "     texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "    logits = transformer(input_ids_pad,\n",
    "                         output_ids_pad,\n",
    "                         texts_en_mask,\n",
    "                         texts_ru_mask,\n",
    "                         texts_en_padding_mask,\n",
    "                         texts_ru_padding_mask,\n",
    "                         texts_en_padding_mask)\n",
    "    pred = logits.argmax(2)[-1]\n",
    "    pred = list(pred.cpu().numpy())\n",
    "    \n",
    "    \n",
    "    check_last = False\n",
    "    \n",
    "    calc_check_last = 0\n",
    "    for i in range(len_sent):\n",
    "        if to_pad_output[i][-1] == tokenizer_ru.token_to_id('[SEP]') or to_pad_output[i][-1] == tokenizer_ru.token_to_id('[PAD]'):\n",
    "            calc_check_last += 1\n",
    "    if calc_check_last == len_sent:\n",
    "        check_last = True\n",
    "\n",
    "    while not check_last:\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            if to_pad_output[i][-1] != tokenizer_ru.token_to_id('[SEP]') and to_pad_output[i][-1] != tokenizer_ru.token_to_id('[PAD]'):\n",
    "                to_pad_output[i].append(pred[i])\n",
    "        \n",
    "\n",
    "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(tpo) for tpo in to_pad_output]).to(DEVICE)\n",
    "\n",
    "        (texts_en_mask,\n",
    "         texts_ru_mask,\n",
    "         texts_en_padding_mask,\n",
    "         texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "        logits = transformer(input_ids_pad,\n",
    "                             output_ids_pad,\n",
    "                             texts_en_mask,\n",
    "                             texts_ru_mask,\n",
    "                             texts_en_padding_mask,\n",
    "                             texts_ru_padding_mask,\n",
    "                             texts_en_padding_mask)\n",
    "        \n",
    "        pred = logits.argmax(2)[-1]\n",
    "        pred = list(pred.cpu().numpy())\n",
    "        \n",
    "        calc_check_last = 0\n",
    "        for i in range(len_sent):\n",
    "            if to_pad_output[i][-1] == tokenizer_ru.token_to_id('[SEP]') or to_pad_output[i][-1] == tokenizer_ru.token_to_id('[PAD]'):\n",
    "                calc_check_last += 1\n",
    "        if calc_check_last == len_sent:\n",
    "            check_last = True\n",
    "        \n",
    "    \n",
    "    res_sents = list()\n",
    "    for j in range(len(to_pad_output)):\n",
    "        res_sents.append(' '.join([tokenizer_ru.id_to_token(i).replace('##', '') for i in to_pad_output[j][1:-1]]))\n",
    "\n",
    "    return ' '.join(res_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "marine-motor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Это немного текст . Пример нескольких предложений . Все работы !'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_news = '''This is some text. THIS IS Example OF several sentences. It is work!'''\n",
    "\n",
    "newtranslate(some_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "healthy-milan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мы можем доверять правительству , чтобы сказать нам правду , в его стрем лении ожидать от Н ЛО ? Е АС СА Е АС СА Е АС СА Е АС СА Е АС СА Е Если Голли вуд за последние годы все , что будет интересно , то есть выводы , можно увлека ться и ча ши ться в тот же момент … в пятницу , Пен та гон Аналоги чно на Рича рда Ди ри су в \" Бли з ко Эн тер пра й з \", я давно я созна лся , в ти ши не . Как такое , я бре вно надеюсь , что недав нее правительство и СМИ пре будут принимать Н ЛО серьезно приведет к какой - то вид \" раскры тие \" раскры тия информации \" Конечно , моя рациональ ная сторона знает , что любое время вы полага ете на правительство или основные средства массовой информации для транспарентности или правды , вы игра ете в пользу мира .'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_news = '''Can we trust the government to tell us the truth in its eagerly awaited report on UFOs? If Hollywood over the years is anything to go by, the findings could be fascinating and chilling at the same time… On Friday, the Pentagon is scheduled to release its highly anticipated report on UFOs, or as the government now calls them, UAPs – unidentified aerial phenomena. Similar to Richard Dreyfuss in ‘Close Encounters of the Third Kind’, I’m a long-time, self-confessed, tin-foil hat-wearing UFO enthusiast/fanatic. As such, I’m delusionally hoping the recent government and media pivot to taking UFOs seriously will lead to some sort of ‘disclosure’, where the truth out there will finally be revealed. Of course, my more rational side knows that any time you’re relying on the government or mainstream media for transparency or truth, you’re playing a fool’s game.'''\n",
    "\n",
    "newtranslate(some_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-baptist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
